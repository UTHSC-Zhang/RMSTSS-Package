---
title: "RMSTdesign:Sample Size and Power Calculations for RMST-based Clinical Trials"
output:
  rmarkdown::html_vignette:
    toc: true
author: "Arnab Aich"
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{RMSTdesign:Sample Size and Power Calculations for RMST-based Clinical Trials}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
biblio-style: apalike
link-citations: yes
---

```{r setup, include=FALSE}
# This setup chunk configures the vignette's appearance and loads necessary packages.
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA,
  fig.align = 'center',
  fig.width = 7,
  fig.height = 5,
  collapse = TRUE
)

packages = c("survival", "dplyr", "tidyr", "knitr", "ggplot2", "mgcv", "kableExtra", "bibtex")
lapply(packages, require, character.only = TRUE)

# In a real package, these functions would be exported and loaded with `library(RMSTdesign)`.
library(RMSTdesign)
```

# Introduction

## The Role of RMST in Clinical Trials

The analysis of time-to-event data has traditionally been dominated by the Cox proportional hazards model, which focuses on the hazard ratio (HR) as the primary measure of treatment effect. However, the HR can be difficult to interpret, especially when the proportional hazards assumption is violated. In such cases, the estimated HR becomes a weighted average that depends on the study's specific censoring pattern, making it difficult to compare results across trials [@tian2014].

The Restricted Mean Survival Time (RMST) has emerged as a robust and clinically intuitive alternative. The RMST is the average event-free time up to a pre-specified time point, $\tau$, and is estimated as the area under the survival curve. This provides a direct measure of survival benefit in units of time (e.g., "days" or "months"), which is often more meaningful to clinicians and patients.

## Direct Modeling of RMST

Instead of estimating RMST indirectly from a survival function, recent methodological advances have focused on modeling the RMST directly as a function of covariates. This approach, analogous to generalized linear models, offers flexibility and clear interpretation of covariate effects. This package, `RMSTdesign`, implements a suite of these modern methods to facilitate the design of clinical trials based on RMST. It provides functions for both power and sample size calculations under various complex scenarios.

## What This Package Offers

`RMSTdesign` provides a comprehensive framework by implementing several key methodologies from the statistical literature:

* **Direct Linear Models**: Based on the seminal work of [@tian2014], these functions model the RMST directly using Inverse Probability of Censoring Weighting (IPCW).
* **Stratified Models**: For studies with nuisance categorical variables (e.g., clinical centers), we provide functions for both **additive** [@zhang2024] and **multiplicative** [@wang2019] models, which efficiently handle stratification without estimating parameters for each level.
* **Dependent Censoring Models**: In settings with competing risks, such as transplantation studies where receiving an organ dependently censors death, we implement methods from [@wang2018].
* **Flexible Non-Linear Models**: For covariates with suspected non-linear effects, the package includes bootstrap-based functions using Generalized Additive Models (GAMs) on pseudo-observations.
* **Analytic vs. Bootstrap Methods**: For many models, the package offers both an `analytical` approach for rapid calculations and a `boot` (bootstrap) approach for enhanced robustness at the cost of computation time.

This vignette will guide you through the theory and application of each of these function groups.

# Linear IPCW Models

These models assume a direct linear relationship between covariates and the RMST. They are the foundational models for direct RMST regression when dealing with independent censoring.

## Theory and Model

Based on the methods of [@tian2014], these functions model the conditional RMST as $$\eta\{\mu(Z)\} = \beta'X$$, where $\eta(\cdot)$ is a link function. To account for right-censoring, the method uses Inverse Probability of Censoring Weighting (IPCW). The weight for an uncensored individual is the inverse of the probability of remaining uncensored up to their event time, where this probability is estimated from a Kaplan-Meier curve of the censoring distribution.

## Analytical Methods

The analytical functions use a formula based on the asymptotic variance of the regression coefficients to calculate power or sample size, making them extremely fast.

### Power Calculation (`linear.power.analytical`)

**Scenario**: We use the `veteran` dataset to estimate power for a trial comparing standard vs. test chemotherapy (`trt`), adjusting for the Karnofsky performance score (`karno`).

```{r echo=FALSE, results='hide'}
# Prepare the veteran dataset
data(veteran)
vet <- veteran %>%
  mutate(
    arm = ifelse(trt == 1, 0, 1),
    status = status
  )
```

First, let's inspect the prepared `veteran` dataset.

```{r}
head(vet)
```

Now, we calculate the power for a range of sample sizes using a truncation time of one year (365 days).

```{r}
# Calculate power
power_results_vet <- linear.power.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(100, 150, 200, 250),
  tau = 365
)
```

The results are returned as a data frame and a `ggplot` object.

```{r}
# Display results table
kbl(power_results_vet$results_data, caption = "Power Analysis for Veteran Dataset") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```



```{r}
# Display enhanced plot
power_results_vet$results_plot +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "#E41A1C") +
  labs(
    title = "Power Curve for Veteran Lung Cancer Trial",
    subtitle = "Linear RMST model, adjusted for Karnofsky score (tau = 365 days)",
    caption = "Red dashed line indicates 80% target power."
  ) +
  theme_bw(base_size = 14)
```

### Sample Size Calculation (`linear.ss.analytical`)

We can also use the analytical method to find the required sample size to achieve a target power.

```{r}
# Find sample size for 80% power
ss_results_vet <- linear.ss.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.80,
  linear_terms = "karno",
  tau = 365
)
```


```{r}
# Display results table
kbl(ss_results_vet$results_data, caption = "Sample Size for Veteran Dataset") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

## Bootstrap Methods

The bootstrap, or simulation-based, approach provides a robust, distribution-free alternative. The `.boot` suffix in the function names is shorthand for 'bootstrap simulation'. This method repeatedly resamples from the pilot data, fits the model on each sample, and calculates power as the proportion of simulations where the treatment effect is significant. While computationally intensive, it makes fewer assumptions.

### Power and Sample Size Calculation (`.boot`)

Here is how you would call the bootstrap functions for power and sample size for the linear model. We set `eval=FALSE` because these chunks can take a long time to run.

```{r, eval=FALSE}
# Power calculation with bootstrap
power_boot_vet <- linear.power.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(150, 200, 250),
  tau = 365,
  n_sim = 200 # Use more simulations (e.g., 1000) in practice
)

# Sample size calculation with bootstrap
ss_boot_vet <- linear.ss.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.80,
  linear_terms = "karno",
  tau = 365,
  n_sim = 200, # Use more simulations in practice
  patience = 2
)
```

# Additive Stratified Models

In many trials, it is necessary to stratify by a categorical variable with many levels, such as clinical center or a discretized biomarker. Estimating a separate parameter for each stratum is inefficient. The additive stratified model elegantly handles this by conditioning out the stratum effect.

## Theory and Model

The semiparametric additive model for RMST, $\mu_{ij} = \mu_{0j} + \beta'Z_i$, assumes that the effect of covariates $Z_i$ is additive and constant across strata $j$, while allowing each stratum to have its own baseline RMST, $\mu_{0j}$. The methods implemented here are based on [@zhang2024], who show that the common effect $\beta$ can be estimated efficiently by using a stratum-centering approach on the IPCW-weighted data, which avoids direct estimation of the numerous $\mu_{0j}$ parameters.

## Analytical Methods

### Sample Size Calculation (`additive.ss.analytical`)

**Scenario**: We use the `colon` dataset to design a trial stratified by the extent of local disease (`extent`), a factor with 4 levels. We want to find the sample size per stratum to achieve 80% power.

```{r echo=FALSE, results='hide'}
# Prepare colon dataset for death endpoint
data(colon)
colon_death <- colon %>%
  filter(etype == 2) %>%
  select(time, status, rx, extent) %>%
  na.omit() %>%
  mutate(
    arm = ifelse(rx == "Obs", 0, 1),
    strata = factor(extent)
  )
```

Let's inspect the prepared `colon` dataset.

```{r}
head(colon_death)
```

Now, we run the sample size search for 80% power, truncating at 5 years (1825 days).

```{r}
# Run the sample size search
ss_results_colon <- additive.ss.analytical(
  pilot_data = colon_death,
  time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  target_power = 0.80,
  tau = 1825,
  n_start = 200, n_step = 50, max_n_per_arm = 1000
)
```



```{r}
# Display results table
kbl(ss_results_colon$results_data, caption = "Sample Size for Stratified Colon Trial") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
# Display enhanced search plot
final_n_colon <- ss_results_colon$results_data$Required_N_per_Stratum
power_at_final_n_colon <- ss_results_colon$results_plot$data %>% 
  filter(N_per_Stratum == final_n_colon) %>% pull(Power)

ss_results_colon$results_plot +
  annotate("rect", xmin = final_n_colon - 25, xmax = final_n_colon + 25, ymin = 0, ymax = power_at_final_n_colon,
           alpha = .2, fill = "#377EB8") +
  annotate("text", x = final_n_colon, y = 0.25,
           label = paste("N =", final_n_colon), color = "#377EB8", angle = 90, vjust = -1, fontface="bold") +
  labs(
    title = "Sample Size Search for Stratified Colon Cancer Trial",
    subtitle = "Additive RMST model with stratification by disease extent (tau = 5 years)"
  ) +
  theme_bw(base_size = 14)
```

# Multiplicative Stratified Models

As an alternative to the additive model, the multiplicative model may be preferred if the treatment is expected to have a relative effect on the RMST.

## Theory and Model

The multiplicative model is of the form $\mu_{ij} = \mu_{0j} \exp(\beta'Z_i)$, where the effect of covariates is a proportional change to the baseline stratum-specific RMST. This is particularly useful for facility profiling, where we might have thousands of centers. The methods implemented here, based on [@wang2019], use a computationally efficient two-stage procedure that avoids creating thousands of indicator variables, making analysis of very large datasets feasible.

## Analytical & Bootstrap Methods

The functions for this model family follow the same pattern (`MS.power.analytical`, `MS.ss.boot`, etc.). Below is a sample call for the analytical sample size function.

```{r, eval=FALSE}
# Note: Using the same colon_death data as the previous section
ms_ss_results_colon <- MS.ss.analytical(
  pilot_data = colon_death,
  time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  target_power = 0.80,
  tau = 1825
)
```

# Semiparametric GAM Models

When a covariate is expected to have a non-linear effect on the outcome, standard linear models may be misspecified. Generalized Additive Models (GAMs) provide a flexible solution.

## Theory and Model

These functions use a bootstrap simulation approach combined with a GAM. The time-to-event outcome is first converted into **jackknife pseudo-observations** for the RMST. A GAM is then fitted to these pseudo-observations, allowing for smooth, non-linear functions of specified covariates using `s()` terms from the `mgcv` package. This approach is powerful but computationally intensive.

## Bootstrap Methods

### Power Calculation (`GAM.power.boot`)

**Scenario**: We use the `gbsg` (German Breast Cancer Study Group) dataset, suspecting that the progesterone receptor count (`pgr`) has a non-linear effect on recurrence-free survival.

```{r echo=FALSE, results='hide'}
# Prepare gbsg dataset
data(gbsg)
gbsg_prepared <- gbsg %>%
  mutate(
    arm = ifelse(hormon == "no", 0, 1)
  )
```

Here is a look at the prepared `gbsg` data.

```{r}
head(gbsg_prepared)
```

The following code shows how to calculate power. We set `eval=FALSE` as it is time-consuming.

```{r, eval=FALSE}
# Calculate power using GAM bootstrap.
# NOTE: n_sim should be higher (e.g., 1000) in practice.
power_gam <- GAM.power.boot(
  pilot_data = gbsg_prepared,
  time_var = "rfstime",
  status_var = "status",
  arm_var = "arm",
  smooth_terms = "pgr", # Model pgr with a smooth term
  sample_sizes = c(150, 200, 250),
  tau = 1825, # 5 years
  n_sim = 100, # Low n_sim for a quick example!
  parallel.cores = 2
)

# kbl(power_gam$results_data)
# print(power_gam$results_plot)
```

# Dependent Censoring Models

In some studies, particularly observational or registry studies, censoring may not be independent of the event of interest. A classic example is in transplant medicine, where receiving an organ (a "good" event) removes a patient from being at risk of pre-transplant death. This is a form of competing risk, or dependent censoring.

## Theory and Model

The methods from [@wang2018] address this by extending the IPCW framework. Instead of a single censoring model, **cause-specific Cox models** are fitted for each source of censoring (e.g., one model for administrative censoring, another for the competing event). The final weight for a subject is a product of the weights derived from all censoring causes, allowing for unbiased estimation of the RMST for the primary event.

## Analytical Methods

### Sample Size Calculation (`DC.ss.analytical`)

**Scenario**: We use the `mgus2` dataset, which tracks patients with a pre-malignant condition. The primary event is progression to cancer (`pstat`=1), but death before progression is a competing risk. We want to find the required sample size to detect an effect on progression, accounting for the competing risk of death.

```{r echo=FALSE, results='hide'}
# Prepare mgus2 data
data(mgus2)
mgus_prepared <- mgus2 %>%
  mutate(
    event_primary = ifelse(pstat == 1, 1, 0),
    event_dependent = ifelse(pstat == 0 & death > 0, 1, 0),
    arm = ifelse(sex == "M", 1, 0)
  ) %>%
  rename(time = futime)
```

First, inspect the prepared `mgus2` dataset. Note the two status columns we created.

```{r}
head(mgus_prepared)
```

Now, find the sample size needed for 80% power, truncating at 10 years (120 months).

```{r}
# Find the sample size
ss_dc_mgus <- DC.ss.analytical(
  pilot_data = mgus_prepared,
  time_var = "time",
  status_var = "event_primary",
  arm_var = "arm",
  dep_cens_status_var = "event_dependent",
  target_power = 0.80,
  linear_terms = "age",
  tau = 120, # 10 years
  n_start = 1000, n_step = 250, max_n_per_arm = 5000
)
```




```{r}
# Display results table
kbl(ss_dc_mgus$results_data, caption = "Sample Size for MGUS Progression Study") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
# Display enhanced plot
final_n_dc <- ss_dc_mgus$results_data$Required_N_per_Arm

ss_dc_mgus$results_plot +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  labs(
    title = "Sample Size Search with Competing Risks",
    subtitle = "Dataset: mgus2. Event: Progression to malignancy. Competing Risk: Death."
  ) +
  theme_bw(base_size = 14)
```

# Conclusion

The `RMSTdesign` package provides a powerful and flexible suite of tools for designing and analyzing clinical trials using the Restricted Mean Survival Time.

## Advantages and Disadvantages

* **Advantages**: The package implements a wide range of modern statistical methods, allowing users to handle complex scenarios like stratification, non-linear effects, and competing risks. The provision of both fast analytical methods and robust bootstrap methods gives users a choice between speed and distributional flexibility.
* **Disadvantages**: The primary limitation is the reliance on representative pilot data. The accuracy of any power or sample size calculation is contingent on the effect sizes and variance structures estimated from the pilot dataset. Furthermore, the bootstrap-based methods can be computationally intensive and may require access to parallel computing resources for timely results.

## Future Work

Future development could involve extending the bootstrap approach to the dependent censoring models and incorporating more advanced model diagnostic tools to help users assess the adequacy of their chosen model based on the pilot data.

# References
