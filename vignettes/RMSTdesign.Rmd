---
title: "RMSTdesign: Sample Size and Power Calculations for RMST-based Clinical Trials"
author: "Arnab Aich"
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: true
    code_folding: hide
    df_print: paged
    highlight: tango
    self_contained: false
bibliography: references.bib
biblio-style: apalike
link-citations: yes
vignette: >
  %\VignetteIndexEntry{RMSTdesign: Sample Size and Power Calculations for RMST-based Clinical Trials}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include=FALSE}
# This setup chunk configures the vignette's appearance and loads necessary packages.
knitr::opts_chunk$set(
   # eval = FALSE,
  message = FALSE,
  warning = FALSE,
  comment = NA,
  eval = FALSE,
  fig.align = 'center',
  fig.width = 7,
  fig.height = 5,
  collapse = TRUE
)
packages = c("survival", "dplyr", "tidyr", "knitr", "ggplot2", "mgcv", "kableExtra", "bibtex")
lapply(packages, require, character.only = TRUE)

library(RMSTdesign)
```

# Introduction

The analysis of time-to-event data has traditionally been dominated by the Cox proportional hazards model, which focuses on the hazard ratio (HR) as the primary measure of treatment effect. However, the HR can be difficult to interpret, especially when the proportional hazards assumption is violated [@tian2014, @zhang2024]. In such cases, the estimated HR becomes a weighted average that depends on the study's specific censoring pattern, making it difficult to compare results across trials [@wang2018]. The Restricted Mean Survival Time (RMST) has emerged as a robust and clinically intuitive alternative, a conclusion supported by a growing body of literature that advocates for its use in the design and analysis of clinical trials [@royston2013, @uno2014]. The RMST is the average event-free time up to a pre-specified time point, $\tau$ , and is estimated as the area under the survival curve. This provides a direct measure of survival benefit in units of time (e.g., "days" or "months"), which is often more meaningful to clinicians and patients.

Instead of estimating RMST indirectly from a survival function, recent methodological advances have focused on modeling the RMST directly as a function of covariates. A foundational paper by [@tian2014] established a class of such models using Inverse Probability of Censoring Weighting (IPCW), which provided the theoretical basis for direct RMST regression. Since then, the literature has rapidly expanded to adapt this direct modeling approach to the complex data structures seen in modern trials. Research has moved beyond a single timepoint to modeling the entire RMST curve as a function of restriction time [@zhao2016, @zhong2022]. Furthermore, to handle the common challenge of adjusting for high-dimensional categorical variables like clinical centers, computationally efficient stratified models were developed, including a multiplicative model by [@wang2019] and a complementary additive model by [@zhang2024]. For observational data, these methods have been extended to estimate causal effects [@ni2021], and for settings with competing risks, such as transplantation studies, [@wang2018] developed a framework to handle dependent censoring using cause-specific weights.

To date, the computational implementation of these sophisticated methods has focused primarily on estimation. For instance, the original papers describe how estimation can be achieved through custom-coded procedures or by cleverly manipulating standard software for weighted least squares or Cox regression [@wang2019, @zhang2024]. However, there is a significant gap between these theoretical estimation frameworks and the availability of validated, user-friendly tools for study design. Calculating the required sample size or statistical power for a trial based on these advanced RMST models is a complex task that, until now, would require bespoke simulation programming from trial statisticians.

This package, RMSTdesign, is designed to fill that critical gap. The primary goal of RMSTdesign is to provide trialists with a comprehensive and accessible suite of tools for power and sample size calculations based on the very latest in direct RMST methodology. It operationalizes the seminal work on direct RMST modeling into a set of validated functions, allowing researchers to robustly design trials for a wide variety of scenarios. RMSTdesign provides a comprehensive framework by implementing several key methodologies from the statistical literature:
`RMSTdesign` provides a comprehensive framework by implementing several key methodologies from the statistical literature:

* **Direct Linear Models**: Based on the seminal work of [@tian2014], these functions model the RMST directly using Inverse Probability of Censoring Weighting (IPCW).
* **Stratified Models**: For studies with nuisance categorical variables (e.g., clinical centers), we provide functions for both **additive** [@zhang2024] and **multiplicative** ([@wang2019]) models, which efficiently handle stratification without estimating parameters for each level.
* **Dependent Censoring Models**: In settings with competing risks, such as transplantation studies where receiving an organ dependently censors death, we implement methods from [@wang2019].
* **Flexible Non-Linear Models**: For covariates with suspected non-linear effects, the package includes bootstrap-based functions using Generalized Additive Models (GAMs) on pseudo-observations.
* **Analytic vs. Bootstrap Methods**: For many models, the package offers both an `analytical` approach for rapid calculations and a `boot` (bootstrap) approach for enhanced robustness at the cost of computation time.

This vignette will guide you through the theory and application of each of these function groups.

# Linear IPCW Models

These models assume a direct linear relationship between covariates and the RMST. They are the foundational models for direct RMST regression when dealing with independent censoring.

## Theory and Model

Based on the methods of [@tian2014], these functions model the conditional RMST as $$\eta\{\mu(Z)\} = \beta'X$$, where $\eta(\cdot)$ is a link function. To account for right-censoring, the method uses Inverse Probability of Censoring Weighting (IPCW). The weight for an uncensored individual is the inverse of the probability of remaining uncensored up to their event time, where this probability is estimated from a Kaplan-Meier curve of the censoring distribution.

## Analytical Methods

The analytical functions use a formula based on the asymptotic variance of the regression coefficients to calculate power or sample size, making them extremely fast.

**Scenario**: We use the `veteran` dataset to estimate power for a trial comparing standard vs. test chemotherapy (`trt`), adjusting for the Karnofsky performance score (`karno`).

### Power Calculation - [`linear.power.analytical`](../reference/linear.power.analytical.html)

First, let's inspect the prepared `veteran` dataset.
```{r veteran_data_prep, echo=FALSE}
vet <- veteran %>%
  mutate(
    arm = ifelse(trt == 1, 0, 1),
    status = status
  )
head(vet)
```

Now, we calculate the power for a range of sample sizes using a truncation time of 9 months year (270 days).

```{r veteran_power_calc}
power_results_vet <- linear.power.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(100, 150, 200, 250),
  tau = 270
)
```

The results are returned as a data frame and a `ggplot` object.

```{r veteran_table_plot, echo=FALSE}

kbl(power_results_vet$results_data , caption = "Power Analysis for Veteran Dataset") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

```

### Sample Size Calculation - [`linear.ss.analytical`](../reference/linear.ss.analytical.html)

We can also use the analytical method to find the required sample size to achieve a target power for a truncation time of an year(365 days) .

```{r veteran_ss_calc}
ss_results_vet <- linear.ss.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.40,
  linear_terms = "karno",
  tau = 365,
  n_start = 1000, n_step = 250, max_n_per_arm = 5000
)
```


```{r veteran_ss_table, echo=FALSE}

kbl(ss_results_vet$results_summary, caption = "Estimated Effect from Pilot Data") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)


ss_results_vet$results_plot +
  theme_bw(base_size = 14)

```

## Bootstrap Methods

The bootstrap, or simulation-based, approach provides a robust, distribution-free alternative. The `.boot` suffix in the function names is shorthand for 'bootstrap simulation'. This method repeatedly resamples from the pilot data, fits the model on each sample, and calculates power as the proportion of simulations where the treatment effect is significant. While computationally intensive, it makes fewer assumptions.

### Power and Sample Size Calculation (`.boot`)

Here is how you would call the bootstrap functions for power for the linear model. The following examples use the same `veteran` dataset, but with a smaller number of simulations for demonstration purposes. In practice, you would use a larger number of simulations (e.g., 1000 or more) to ensure stability of the results. 

First we calculate the power for a range of sample sizes. The [`linear.power.boot`](../reference/linear.power.boot.html) function takes the pilot data and returns a data frame with the estimated power for each sample size.

```{r linear_boot_example}
power_boot_vet <- linear.power.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(150, 200, 250),
  tau = 365,
  n_sim = 200 
)
```


```{r echo=FALSE}
power_boot_vet$results_plot
```


Here is how you would call the bootstrap function for sample size calculation. We will use the function [`linear.ss.boot`](../reference/linear.ss.boot.html) to find the sample size needed to achieve a target power of 0.5, truncating at 180 days (6 months).
```{r}
ss_boot_vet <- linear.ss.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.5,
  linear_terms = "karno",
  tau = 180,
  n_sim = 500, 
  patience = 5
)
```



```{r echo=FALSE}

ss_boot_vet$results_plot +
  theme_bw(base_size = 14)
```


# Additive Stratified Models

In many trials, it is necessary to stratify by a categorical variable with many levels, such as clinical center or a discretized biomarker. Estimating a separate parameter for each stratum is inefficient. The additive stratified model elegantly handles this by conditioning out the stratum effect.

## Theory and Model

The semiparametric additive model for RMST, $$\mu_{ij} = \mu_{0j} + \beta'Z_i$$, assumes that the effect of covariates $Z_i$ is additive and constant across strata $j$, while allowing each stratum to have its own baseline RMST, $\mu_{0j}$. The methods implemented here are based on Zhang & Schaubel (2024), who show that the common effect $\beta$ can be estimated efficiently by using a stratum-centering approach on the IPCW-weighted data, which avoids direct estimation of the numerous $\mu_{0j}$ parameters.

## Analytical Methods

### Sample Size Calculation - [`additive.ss.analytical`](../reference/additive.ss.analytical.html)

**Scenario**: We use the `colon` dataset to design a trial stratified by the extent of local disease (`extent`), a factor with 4 levels. We want to find the sample size per stratum to achieve 80% power.
Let's inspect the prepared `colon` dataset.
```{r colon_data_prep, echo=FALSE}
colon_death <- colon %>%
  filter(etype == 2) %>%
  select(time, status, rx, extent) %>%
  na.omit() %>%
  mutate(
    arm = ifelse(rx == "Obs", 0, 1),
    status = status,
    strata = factor(extent)
  )
head(colon_death)
```

Now, we run the sample size search for 80% power, truncating at 5 years (1825 days).

```{r colon_ss_calc}
ss_results_colon <- additive.ss.analytical(
  pilot_data = colon_death,
  time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  target_power = 0.60,
  tau = 1825,
  n_start = 100, n_step = 100, max_n_per_arm = 10000
)
```

```{r colon_ss_table, echo=FALSE}

kbl(ss_results_colon$results_summary , caption = "Estimated Effect from Pilot Data") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
# Display enhanced search plot
final_n_colon <- ss_results_colon$results_data$Required_N_per_Stratum
power_at_final_n_colon <- ss_results_colon$results_plot$data %>% 
  filter(N_per_Stratum == final_n_colon) %>% pull(Power)

ss_results_colon$results_plot

```

### Power Calculation - [`additive.power.analytical`](../reference/additive.power.analytical.html)

This function calculates the power for a given set of sample sizes in a stratified additive model. We will use the `colon` dataset again for this example.

```{r additive_power_calc}
# Calculate power for a range of sample sizes per stratum
power_results_colon <- additive.power.analytical(
  pilot_data = colon_death,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  strata_var = "strata",
  sample_sizes = c(1000, 3000, 5000),
  tau = 1825 # 5 years
)

```


```{r additive_power_table_plot, echo=FALSE}
# Display the results
kbl(power_results_colon$results_data, caption = "Power for Additive Stratified Colon Trial") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

power_results_colon$results_plot +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  labs(title = "Power Curve for Additive Stratified Model") +
  theme_bw(base_size = 14)
```


# Multiplicative Stratified Models

As an alternative to the additive model, the multiplicative model may be preferred if the treatment is expected to have a relative effect on the RMST, such as increasing or decreasing survival time by a certain percentage.

## Theory and Model

The multiplicative model is of the form $$\mu_{ij} = \mu_{0j} \exp(\beta'Z_i)$$, where the effect of covariates is a proportional change to the baseline stratum-specific RMST. This is particularly useful for facility profiling, where we might have thousands of centers. The methods implemented here, based on [@wang2019], use a computationally efficient two-stage procedure that avoids creating thousands of indicator variables, making analysis of very large datasets feasible.

## Analytical Methods

### Power Calculation - [`MS.power.analytical`](../reference/MS.power.analytical.html)

This function calculates the power for various sample sizes using the analytical method for the multiplicative stratified model.

```{r ms_power_analytical_example}
# Calculate power using the multiplicative stratified analytical method
power_ms_analytical <- MS.power.analytical(
  pilot_data = colon_death,
  time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  sample_sizes = c(300, 400, 500),
  tau = 1825
)
```


```{r echo=FALSE}

kbl(power_ms_analytical$results_data, caption = "Power for Multiplicative Stratified Model") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

### Sample Size Calculation - [`MS.ss.analytical`](../reference/MS.ss.analytical.html)

The following example demonstrates the sample size calculation using the same model.

```{r ms_ss_analytical_example}
# Calculate sample size
ms_ss_results_colon <- MS.ss.analytical(
  pilot_data = colon_death, time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  target_power = 0.6,tau = 1825)
```

```{r echo=FALSE}

kbl(ms_ss_results_colon$results_summary, caption = "Sample Size for Multiplicative Stratified Model") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

ms_ss_results_colon$results_plot +
  theme_bw(base_size = 14)
```

## Bootstrap Methods

The bootstrap approach provides a more robust, simulation-based analysis for the multiplicative model.

### Power Calculation - [`MS.power.boot`](../reference/MS.power.boot.html)

The following code demonstrates how to call the `MS.power.boot` function. 

```{r ms_power_boot_example}
power_ms_boot <- MS.power.boot(
  pilot_data = colon_death,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  strata_var = "strata",
  sample_sizes = c(100, 300, 500),
  tau = 1825,
  n_sim = 100, 
  parallel.cores = 10 
)
```

```{r echo=FALSE}
kbl(power_ms_boot$results_summary, caption = "Power for Multiplicative Stratified Model (Bootstrap)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
power_ms_boot$results_plot 
```


### Sample Size Calculation - [`MS.ss.boot`](../reference/MS.ss.boot.html)

Similarly, the sample size can be calculated using bootstrap simulation. 

```{r ms_ss_boot_example}
ss_ms_boot <- MS.ss.boot(
  pilot_data = colon_death,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  strata_var = "strata", 
  target_power = 0.5,
  tau = 1825,
  n_sim = 100,
  n_start = 100,
  n_step = 50,
  patience = 4,
  parallel.cores = 10
)
```


```{r echo=FALSE}

kbl(ss_ms_boot$results_summary, caption = "Sample Size for Multiplicative Stratified Model (Bootstrap)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

# Semiparametric GAM Models

When a covariate is expected to have a non-linear effect on the outcome, standard linear models may be misspecified. Generalized Additive Models (GAMs) provide a flexible solution.

## Theory and Model

These functions use a bootstrap simulation approach combined with a GAM. The time-to-event outcome is first converted into **jackknife pseudo-observations** for the RMST. A GAM is then fitted to these pseudo-observations, allowing for smooth, non-linear functions of specified covariates using `s()` terms from the `mgcv` package. This approach is powerful but computationally intensive.

## Bootstrap Methods

### Power Calculation - [`GAM.power.boot`](../reference/GAM.power.boot.html)

**Scenario**: We use the `gbsg` (German Breast Cancer Study Group) dataset, suspecting that the progesterone receptor count (`pgr`) has a non-linear effect on recurrence-free survival.
Here is a look at the prepared `gbsg` data.
```{r gbsg_data_prep, echo=FALSE}
gbsg_prepared <- gbsg %>%
  mutate(
    arm = ifelse(hormon == "no", 0, 1)
  )
head(gbsg_prepared)
```

The following code shows how to calculate power.

```{r gbsg_power_calc}
power_gam <- GAM.power.boot(
  pilot_data = gbsg_prepared,
  time_var = "rfstime",
  status_var = "status",
  arm_var = "arm",
  smooth_terms = "pgr", # Model pgr with a smooth term
  sample_sizes = c(50, 200, 400),
  tau = 2825, # 5 years
  n_sim = 500,
  parallel.cores = 10
)

print(power_gam$results_plot)
```

### Sample Size Calculation - [`GAM.ss.boot`](../reference/GAM.ss.boot.html)
**Scenario**: We want to find the sample size needed to achieve 80% power for detecting an effect of `pgr` on recurrence-free survival.
```{r}
ss_gam <- GAM.ss.boot(
  pilot_data = gbsg_prepared,
  time_var = "rfstime",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.95,
  tau = 182, 
  n_sim = 500, 
  patience = 5,
  parallel.cores = 10
)
```

```{r echo=FALSE}
ss_gam$results_plot +
  theme_bw(base_size = 14)
```

# Dependent Censoring Models

In some studies, particularly observational or registry studies, censoring may not be independent of the event of interest. A classic example is in transplant medicine, where receiving an organ (a "good" event) removes a patient from being at risk of pre-transplant death. This is a form of competing risk, or dependent censoring.

## Theory and Model

The methods from [@wang2019] address this by extending the IPCW framework. Instead of a single censoring model, **cause-specific Cox models** are fitted for each source of censoring (e.g., one model for administrative censoring, another for the competing event). The final weight for a subject is a product of the weights derived from all censoring causes, allowing for unbiased estimation of the RMST for the primary event. We will use the `mgus2` dataset for this scenario.

```{r mgus2_data_prep, echo=FALSE}
mgus_prepared <- mgus2 %>%
  mutate(
    event_primary = ifelse(pstat == 1, 1, 0),
    event_dependent = ifelse(pstat == 0 & death > 0, 1, 0),
    arm = ifelse(sex == "M", 1, 0)
  ) %>%
  rename(time = futime)
head(mgus_prepared)
```
## Analytical Methods

### Power Calculation - [`DC.power.analytical`](../reference/DC.power.analytical.html)

This function calculates power for a study with dependent censoring (competing risks) for a given set of sample sizes. 
```{r dc_power_calc}
dc_power_results <- DC.power.analytical(
  pilot_data = mgus_prepared,
  time_var = "time",
  status_var = "event_primary",
  arm_var = "arm",
  dep_cens_status_var = "event_dependent",
  sample_sizes = c(100, 250, 500),
  linear_terms = "age",
  tau = 120 # 10 years
)
```

```{r echo=FALSE}
kbl(dc_power_results$results_summary, caption = "Power Analysis for MGUS Progression Study") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

dc_power_results$results_plot
```

### Sample Size Calculation - [`DC.ss.analytical`](../reference/DC.ss.analytical.html)

Now, find the sample size needed for 80% power, truncating at 10 years (120 months).

```{r mgus2_ss_calc}
ss_dc_mgus <- DC.ss.analytical(
  pilot_data = mgus_prepared,
  time_var = "time",
  status_var = "event_primary",
  arm_var = "arm",
  dep_cens_status_var = "event_dependent",
  target_power = 0.80,
  linear_terms = "age",
  tau = 120, # 10 years
  n_start = 100, n_step = 50, max_n_per_arm = 5000
)

```


```{r mgus2_table, echo=FALSE}

kbl(ss_dc_mgus$results_summary, caption = "Estimated Effect from Pilot Data") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)

ss_dc_mgus$results_plot +
  theme_bw(base_size = 14)

```

# Conclusion

The `RMSTdesign` package provides a powerful and flexible suite of tools for designing and analyzing clinical trials using the Restricted Mean Survival Time.

## Advantages and Disadvantages

* **Advantages**: The package implements a wide range of modern statistical methods, allowing users to handle complex scenarios like stratification, non-linear effects, and competing risks. The provision of both fast analytical methods and robust bootstrap methods gives users a choice between speed and distributional flexibility.
* **Disadvantages**: The primary limitation is the reliance on representative pilot data. The accuracy of any power or sample size calculation is contingent on the effect sizes and variance structures estimated from the pilot dataset. Furthermore, the bootstrap-based methods can be computationally intensive and may require access to parallel computing resources for timely results.

## Future Work

Future development could involve extending the bootstrap approach to the dependent censoring models and incorporating more advanced model diagnostic tools to help users assess the adequacy of their chosen model based on the pilot data.


# References

